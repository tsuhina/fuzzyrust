{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Resume-Job Matching: Building a Talent Search Engine\n",
        "\n",
        "## The Challenge\n",
        "\n",
        "Recruiting teams face a fundamental matching problem:\n",
        "\n",
        "1. **Skill Terminology Varies**: \"React.js\" vs \"ReactJS\" vs \"React\" are the same skill\n",
        "2. **Job Titles Are Inconsistent**: \"Software Engineer\" vs \"Developer\" vs \"Programmer\"\n",
        "3. **Multi-Dimensional Matching**: Skills + experience + location + salary all matter\n",
        "4. **Volume**: Enterprise ATS systems process thousands of resumes per job posting\n",
        "\n",
        "Manual resume screening is expensive (~$15-20 per resume for recruiter time). Automated matching can pre-filter candidates, letting recruiters focus on qualified applicants.\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "- Using **TokenSet** field type for skill list matching\n",
        "- **SchemaIndex** for multi-field candidate scoring\n",
        "- Building a skills normalization system\n",
        "- Weighting strategies for required vs. nice-to-have skills\n",
        "- Creating a complete talent matching pipeline\n",
        "\n",
        "## Dataset\n",
        "\n",
        "We'll use a **skills taxonomy** based on:\n",
        "- O*NET (Occupational Information Network) skill categories\n",
        "- Common tech industry variations\n",
        "- Embedded sample data for demonstration\n",
        "\n",
        "For production use, consider:\n",
        "- [O*NET Database](https://www.onetcenter.org/database.html) (free, comprehensive)\n",
        "- [LinkedIn Skills API](https://docs.microsoft.com/en-us/linkedin/) (requires partnership)\n",
        "- [ESCO Skills Taxonomy](https://esco.ec.europa.eu/) (EU standard)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fuzzyrust as fr\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "print(f\"FuzzyRust loaded for talent matching\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. The Skill Matching Problem\n",
        "\n",
        "Skills are messy. The same capability can be written many ways:\n",
        "\n",
        "| Resume Says | Job Requires | Are They the Same? |\n",
        "|-------------|--------------|--------------------|\n",
        "| \"React.js\" | \"ReactJS\" | Yes |\n",
        "| \"Python 3\" | \"Python\" | Yes (superset) |\n",
        "| \"AWS\" | \"Amazon Web Services\" | Yes (abbreviation) |\n",
        "| \"Machine Learning\" | \"ML\" | Yes |\n",
        "| \"Data Science\" | \"Machine Learning\" | Partial overlap |\n",
        "| \"JavaScript\" | \"Java\" | NO! Common confusion |\n",
        "\n",
        "Simple string matching fails. We need:\n",
        "1. **Skill normalization**: Map variants to canonical forms\n",
        "2. **Set-based matching**: Compare skill sets, not individual strings\n",
        "3. **Weighted scoring**: Some skills matter more than others"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrate why simple string matching fails\n",
        "skill_pairs = [\n",
        "    (\"React.js\", \"ReactJS\"),\n",
        "    (\"Python 3\", \"Python\"),\n",
        "    (\"AWS\", \"Amazon Web Services\"),\n",
        "    (\"Machine Learning\", \"ML\"),\n",
        "    (\"JavaScript\", \"Java\"),  # Should NOT match!\n",
        "]\n",
        "\n",
        "print(f\"{'Skill 1':<25} {'Skill 2':<25} {'Levenshtein':<12} {'Jaro-Winkler'}\")\n",
        "print(\"=\" * 75)\n",
        "\n",
        "for s1, s2 in skill_pairs:\n",
        "    lev = fr.levenshtein_similarity(s1.lower(), s2.lower())\n",
        "    jw = fr.jaro_winkler_similarity(s1.lower(), s2.lower())\n",
        "    \n",
        "    # Flag dangerous false positives\n",
        "    warning = \"  DANGER!\" if s1 == \"JavaScript\" and jw > 0.7 else \"\"\n",
        "    print(f\"{s1:<25} {s2:<25} {lev:.2%}        {jw:.2%}{warning}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Key Insight**: Jaro-Winkler gives JavaScript and Java a 78% similarity score - a dangerous false positive! We need domain-specific skill normalization, not just string similarity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Building a Skills Taxonomy\n",
        "\n",
        "A skills taxonomy maps variations to canonical forms and defines relationships:\n",
        "\n",
        "```\n",
        "\"react\" (canonical)\n",
        "  ├── \"react.js\" (alias)\n",
        "  ├── \"reactjs\" (alias)\n",
        "  └── \"react js\" (alias)\n",
        "\n",
        "\"python\" (canonical)\n",
        "  ├── \"python 2\" (implies python)\n",
        "  ├── \"python 3\" (implies python)\n",
        "  └── \"py\" (abbreviation)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive tech skills taxonomy\n",
        "SKILLS_TAXONOMY = {\n",
        "    # Programming Languages\n",
        "    'python': ['python', 'python3', 'python 3', 'python2', 'python 2', 'py'],\n",
        "    'javascript': ['javascript', 'js', 'ecmascript', 'es6', 'es2015', 'es2020'],\n",
        "    'typescript': ['typescript', 'ts'],\n",
        "    'java': ['java', 'java8', 'java 8', 'java11', 'java 11', 'java17'],\n",
        "    'csharp': ['c#', 'csharp', 'c sharp', '.net c#'],\n",
        "    'cpp': ['c++', 'cpp', 'cplusplus'],\n",
        "    'c': ['c language', 'c programming'],\n",
        "    'go': ['go', 'golang', 'go lang'],\n",
        "    'rust': ['rust', 'rust lang', 'rustlang'],\n",
        "    'ruby': ['ruby', 'ruby on rails', 'ror'],\n",
        "    'php': ['php', 'php7', 'php8'],\n",
        "    'swift': ['swift', 'swift 5', 'swiftui'],\n",
        "    'kotlin': ['kotlin', 'kt'],\n",
        "    'scala': ['scala'],\n",
        "    'r': ['r', 'r programming', 'r language', 'rlang'],\n",
        "    'sql': ['sql', 'structured query language', 'tsql', 't-sql', 'plsql', 'pl/sql'],\n",
        "    \n",
        "    # Frontend Frameworks\n",
        "    'react': ['react', 'react.js', 'reactjs', 'react js'],\n",
        "    'angular': ['angular', 'angularjs', 'angular.js', 'angular 2+'],\n",
        "    'vue': ['vue', 'vue.js', 'vuejs', 'vue 3'],\n",
        "    'svelte': ['svelte', 'sveltejs'],\n",
        "    'nextjs': ['next.js', 'nextjs', 'next js'],\n",
        "    'jquery': ['jquery', 'jquery ui'],\n",
        "    \n",
        "    # Backend Frameworks\n",
        "    'nodejs': ['node.js', 'nodejs', 'node js', 'node'],\n",
        "    'express': ['express', 'express.js', 'expressjs'],\n",
        "    'django': ['django', 'django rest', 'drf'],\n",
        "    'flask': ['flask'],\n",
        "    'fastapi': ['fastapi', 'fast api'],\n",
        "    'spring': ['spring', 'spring boot', 'springboot', 'spring framework'],\n",
        "    'rails': ['rails', 'ruby on rails', 'ror'],\n",
        "    'laravel': ['laravel'],\n",
        "    'dotnet': ['.net', 'dotnet', '.net core', 'asp.net', 'aspnet'],\n",
        "    \n",
        "    # Cloud Platforms\n",
        "    'aws': ['aws', 'amazon web services', 'amazon aws'],\n",
        "    'azure': ['azure', 'microsoft azure', 'ms azure'],\n",
        "    'gcp': ['gcp', 'google cloud', 'google cloud platform'],\n",
        "    'heroku': ['heroku'],\n",
        "    'digitalocean': ['digitalocean', 'digital ocean', 'do'],\n",
        "    \n",
        "    # DevOps & Infrastructure\n",
        "    'docker': ['docker', 'docker compose', 'dockerfile'],\n",
        "    'kubernetes': ['kubernetes', 'k8s', 'kube'],\n",
        "    'terraform': ['terraform', 'tf', 'hashicorp terraform'],\n",
        "    'ansible': ['ansible'],\n",
        "    'jenkins': ['jenkins', 'jenkins ci'],\n",
        "    'cicd': ['ci/cd', 'cicd', 'ci cd', 'continuous integration', 'continuous deployment'],\n",
        "    'git': ['git', 'github', 'gitlab', 'bitbucket', 'version control'],\n",
        "    'linux': ['linux', 'unix', 'ubuntu', 'centos', 'debian', 'rhel'],\n",
        "    \n",
        "    # Databases\n",
        "    'postgresql': ['postgresql', 'postgres', 'psql', 'pg'],\n",
        "    'mysql': ['mysql', 'mariadb'],\n",
        "    'mongodb': ['mongodb', 'mongo', 'mongoose'],\n",
        "    'redis': ['redis'],\n",
        "    'elasticsearch': ['elasticsearch', 'elastic', 'es', 'elk'],\n",
        "    'dynamodb': ['dynamodb', 'dynamo db', 'aws dynamodb'],\n",
        "    'cassandra': ['cassandra', 'apache cassandra'],\n",
        "    \n",
        "    # Data Science & ML\n",
        "    'machine_learning': ['machine learning', 'ml', 'statistical learning'],\n",
        "    'deep_learning': ['deep learning', 'dl', 'neural networks', 'nn'],\n",
        "    'tensorflow': ['tensorflow', 'tf', 'keras'],\n",
        "    'pytorch': ['pytorch', 'torch'],\n",
        "    'pandas': ['pandas', 'python pandas'],\n",
        "    'numpy': ['numpy', 'np'],\n",
        "    'scikit_learn': ['scikit-learn', 'sklearn', 'scikit learn'],\n",
        "    'nlp': ['nlp', 'natural language processing', 'text analytics'],\n",
        "    'computer_vision': ['computer vision', 'cv', 'image processing', 'opencv'],\n",
        "    'data_analysis': ['data analysis', 'data analytics', 'analytics'],\n",
        "    'data_visualization': ['data visualization', 'tableau', 'power bi', 'looker'],\n",
        "    \n",
        "    # Soft Skills (often in job postings)\n",
        "    'communication': ['communication', 'communication skills', 'written communication', 'verbal communication'],\n",
        "    'teamwork': ['teamwork', 'team player', 'collaboration', 'collaborative'],\n",
        "    'leadership': ['leadership', 'team lead', 'tech lead', 'management'],\n",
        "    'problem_solving': ['problem solving', 'problem-solving', 'analytical thinking', 'critical thinking'],\n",
        "    'agile': ['agile', 'scrum', 'kanban', 'agile methodology', 'sprint planning'],\n",
        "}\n",
        "\n",
        "# Build reverse lookup: variation -> canonical\n",
        "SKILL_ALIASES = {}\n",
        "for canonical, variations in SKILLS_TAXONOMY.items():\n",
        "    for var in variations:\n",
        "        SKILL_ALIASES[var.lower()] = canonical\n",
        "\n",
        "print(f\"Taxonomy contains {len(SKILLS_TAXONOMY)} canonical skills\")\n",
        "print(f\"Total aliases: {len(SKILL_ALIASES)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def normalize_skill(skill: str) -> str:\n",
        "    \"\"\"\n",
        "    Normalize a skill to its canonical form.\n",
        "    \n",
        "    Returns the canonical skill name, or the cleaned input if unknown.\n",
        "    \"\"\"\n",
        "    # Clean the skill\n",
        "    cleaned = skill.lower().strip()\n",
        "    \n",
        "    # Remove version numbers (e.g., \"Python 3.9\" -> \"python\")\n",
        "    cleaned = re.sub(r'\\s+\\d+\\.?\\d*', '', cleaned)\n",
        "    \n",
        "    # Check direct alias match\n",
        "    if cleaned in SKILL_ALIASES:\n",
        "        return SKILL_ALIASES[cleaned]\n",
        "    \n",
        "    # Try without punctuation\n",
        "    no_punct = re.sub(r'[^a-z0-9\\s]', '', cleaned)\n",
        "    if no_punct in SKILL_ALIASES:\n",
        "        return SKILL_ALIASES[no_punct]\n",
        "    \n",
        "    # Return cleaned version if no match\n",
        "    return cleaned\n",
        "\n",
        "\n",
        "def normalize_skills(skills: list) -> list:\n",
        "    \"\"\"\n",
        "    Normalize a list of skills, removing duplicates.\n",
        "    \"\"\"\n",
        "    normalized = set()\n",
        "    for skill in skills:\n",
        "        norm = normalize_skill(skill)\n",
        "        if norm:\n",
        "            normalized.add(norm)\n",
        "    return sorted(normalized)\n",
        "\n",
        "\n",
        "# Test normalization\n",
        "test_skills = [\n",
        "    \"React.js\",\n",
        "    \"Python 3.9\",\n",
        "    \"Amazon Web Services\",\n",
        "    \"K8s\",\n",
        "    \"node.js\",\n",
        "    \"Machine Learning\",\n",
        "    \"scikit-learn\",\n",
        "    \"Unknown Skill XYZ\",  # Should pass through\n",
        "]\n",
        "\n",
        "print(\"Skill Normalization:\")\n",
        "print(\"-\" * 50)\n",
        "for skill in test_skills:\n",
        "    norm = normalize_skill(skill)\n",
        "    status = \"(known)\" if norm in SKILLS_TAXONOMY else \"(unknown)\"\n",
        "    print(f\"{skill:<25} -> {norm:<20} {status}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Sample Data: Jobs and Candidates\n",
        "\n",
        "Let's create realistic job postings and candidate profiles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample job postings\n",
        "JOB_POSTINGS = [\n",
        "    {\n",
        "        'id': 'JOB001',\n",
        "        'title': 'Senior Full Stack Developer',\n",
        "        'company': 'TechCorp',\n",
        "        'location': 'San Francisco, CA',\n",
        "        'required_skills': ['React', 'Node.js', 'PostgreSQL', 'TypeScript', 'AWS'],\n",
        "        'nice_to_have': ['GraphQL', 'Docker', 'Kubernetes', 'CI/CD'],\n",
        "        'experience_years': 5,\n",
        "        'description': 'Looking for a senior full stack developer to build scalable web applications.'\n",
        "    },\n",
        "    {\n",
        "        'id': 'JOB002',\n",
        "        'title': 'Machine Learning Engineer',\n",
        "        'company': 'AI Startup',\n",
        "        'location': 'Remote',\n",
        "        'required_skills': ['Python', 'Machine Learning', 'TensorFlow', 'SQL'],\n",
        "        'nice_to_have': ['PyTorch', 'NLP', 'Computer Vision', 'AWS', 'Docker'],\n",
        "        'experience_years': 3,\n",
        "        'description': 'Join our ML team to build cutting-edge AI models for production systems.'\n",
        "    },\n",
        "    {\n",
        "        'id': 'JOB003',\n",
        "        'title': 'DevOps Engineer',\n",
        "        'company': 'CloudScale',\n",
        "        'location': 'New York, NY',\n",
        "        'required_skills': ['AWS', 'Kubernetes', 'Terraform', 'Linux', 'CI/CD'],\n",
        "        'nice_to_have': ['Python', 'Go', 'Ansible', 'Prometheus', 'Grafana'],\n",
        "        'experience_years': 4,\n",
        "        'description': 'Build and maintain cloud infrastructure for high-traffic applications.'\n",
        "    },\n",
        "    {\n",
        "        'id': 'JOB004',\n",
        "        'title': 'Frontend Developer',\n",
        "        'company': 'DesignFirst',\n",
        "        'location': 'Austin, TX',\n",
        "        'required_skills': ['JavaScript', 'React', 'CSS', 'HTML'],\n",
        "        'nice_to_have': ['TypeScript', 'Next.js', 'Testing', 'Accessibility'],\n",
        "        'experience_years': 2,\n",
        "        'description': 'Create beautiful, responsive user interfaces for web applications.'\n",
        "    },\n",
        "]\n",
        "\n",
        "# Sample candidate profiles\n",
        "CANDIDATES = [\n",
        "    {\n",
        "        'id': 'CAND001',\n",
        "        'name': 'Alice Johnson',\n",
        "        'title': 'Full Stack Software Engineer',\n",
        "        'location': 'San Francisco, CA',\n",
        "        'skills': ['React.js', 'Node.js', 'PostgreSQL', 'TypeScript', 'AWS', 'Docker', 'Git'],\n",
        "        'experience_years': 6,\n",
        "        'summary': 'Experienced full stack developer with focus on scalable web applications.'\n",
        "    },\n",
        "    {\n",
        "        'id': 'CAND002',\n",
        "        'name': 'Bob Smith',\n",
        "        'title': 'Data Scientist',\n",
        "        'location': 'Remote',\n",
        "        'skills': ['Python 3', 'Machine Learning', 'TensorFlow', 'PyTorch', 'SQL', 'Pandas', 'Scikit-learn'],\n",
        "        'experience_years': 4,\n",
        "        'summary': 'ML engineer specializing in NLP and recommendation systems.'\n",
        "    },\n",
        "    {\n",
        "        'id': 'CAND003',\n",
        "        'name': 'Carol Davis',\n",
        "        'title': 'Cloud Infrastructure Engineer',\n",
        "        'location': 'Seattle, WA',\n",
        "        'skills': ['Amazon Web Services', 'K8s', 'Terraform', 'Linux', 'CI/CD', 'Python', 'Go'],\n",
        "        'experience_years': 5,\n",
        "        'summary': 'DevOps specialist with expertise in cloud-native architectures.'\n",
        "    },\n",
        "    {\n",
        "        'id': 'CAND004',\n",
        "        'name': 'David Lee',\n",
        "        'title': 'Junior Web Developer',\n",
        "        'location': 'Austin, TX',\n",
        "        'skills': ['JavaScript', 'React', 'HTML', 'CSS', 'Git'],\n",
        "        'experience_years': 1,\n",
        "        'summary': 'Recent bootcamp graduate passionate about frontend development.'\n",
        "    },\n",
        "    {\n",
        "        'id': 'CAND005',\n",
        "        'name': 'Eva Martinez',\n",
        "        'title': 'Backend Developer',\n",
        "        'location': 'Los Angeles, CA',\n",
        "        'skills': ['Java', 'Spring Boot', 'MySQL', 'AWS', 'Docker'],\n",
        "        'experience_years': 4,\n",
        "        'summary': 'Backend engineer experienced with enterprise Java applications.'\n",
        "    },\n",
        "]\n",
        "\n",
        "print(f\"Loaded {len(JOB_POSTINGS)} job postings\")\n",
        "print(f\"Loaded {len(CANDIDATES)} candidates\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Skill-Based Matching\n",
        "\n",
        "The core of talent matching is comparing skill sets. We need to:\n",
        "\n",
        "1. Normalize skills to canonical forms\n",
        "2. Calculate overlap between candidate skills and job requirements\n",
        "3. Weight required skills higher than nice-to-have\n",
        "\n",
        "**Jaccard similarity** is ideal for set comparison:\n",
        "```\n",
        "Jaccard(A, B) = |A ∩ B| / |A ∪ B|\n",
        "```\n",
        "\n",
        "FuzzyRust's **TokenSet** field type handles this automatically."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_skill_match(candidate_skills: list, required_skills: list, \n",
        "                          nice_to_have: list = None) -> dict:\n",
        "    \"\"\"\n",
        "    Calculate how well a candidate's skills match job requirements.\n",
        "    \n",
        "    Returns:\n",
        "        {\n",
        "            'required_match': % of required skills matched,\n",
        "            'nice_to_have_match': % of nice-to-have matched,\n",
        "            'overall_score': weighted score,\n",
        "            'matched_required': list of matched required skills,\n",
        "            'missing_required': list of missing required skills,\n",
        "            'matched_nice_to_have': list of matched nice-to-have\n",
        "        }\n",
        "    \"\"\"\n",
        "    # Normalize all skills\n",
        "    cand_norm = set(normalize_skills(candidate_skills))\n",
        "    req_norm = set(normalize_skills(required_skills))\n",
        "    nice_norm = set(normalize_skills(nice_to_have or []))\n",
        "    \n",
        "    # Calculate matches\n",
        "    matched_required = cand_norm & req_norm\n",
        "    missing_required = req_norm - cand_norm\n",
        "    matched_nice = cand_norm & nice_norm\n",
        "    \n",
        "    # Calculate scores\n",
        "    required_score = len(matched_required) / len(req_norm) if req_norm else 0\n",
        "    nice_score = len(matched_nice) / len(nice_norm) if nice_norm else 0\n",
        "    \n",
        "    # Weighted overall score (required 70%, nice-to-have 30%)\n",
        "    overall = (required_score * 0.7) + (nice_score * 0.3)\n",
        "    \n",
        "    return {\n",
        "        'required_match': required_score,\n",
        "        'nice_to_have_match': nice_score,\n",
        "        'overall_score': overall,\n",
        "        'matched_required': sorted(matched_required),\n",
        "        'missing_required': sorted(missing_required),\n",
        "        'matched_nice_to_have': sorted(matched_nice)\n",
        "    }\n",
        "\n",
        "\n",
        "# Test skill matching\n",
        "job = JOB_POSTINGS[0]  # Senior Full Stack Developer\n",
        "candidate = CANDIDATES[0]  # Alice Johnson\n",
        "\n",
        "print(f\"Job: {job['title']} at {job['company']}\")\n",
        "print(f\"Required: {job['required_skills']}\")\n",
        "print(f\"Nice-to-have: {job['nice_to_have']}\")\n",
        "print()\n",
        "print(f\"Candidate: {candidate['name']}\")\n",
        "print(f\"Skills: {candidate['skills']}\")\n",
        "print()\n",
        "\n",
        "match = calculate_skill_match(\n",
        "    candidate['skills'],\n",
        "    job['required_skills'],\n",
        "    job['nice_to_have']\n",
        ")\n",
        "\n",
        "print(\"Match Analysis:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Required skills match: {match['required_match']:.0%}\")\n",
        "print(f\"Nice-to-have match: {match['nice_to_have_match']:.0%}\")\n",
        "print(f\"Overall score: {match['overall_score']:.0%}\")\n",
        "print(f\"\")\n",
        "print(f\"Matched required: {match['matched_required']}\")\n",
        "print(f\"Missing required: {match['missing_required']}\")\n",
        "print(f\"Matched nice-to-have: {match['matched_nice_to_have']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Multi-Field Matching with SchemaIndex\n",
        "\n",
        "Skills aren't everything. A complete talent match should consider:\n",
        "\n",
        "- **Job Title**: \"Frontend Developer\" should match \"UI Engineer\"\n",
        "- **Skills**: The core match (highest weight)\n",
        "- **Location**: Geographic proximity or remote work\n",
        "- **Experience**: Years of experience vs. requirements\n",
        "\n",
        "SchemaIndex lets us combine all these factors with configurable weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TalentMatcher:\n",
        "    \"\"\"\n",
        "    Multi-field talent matching system using SchemaIndex.\n",
        "    \n",
        "    Matches candidates to jobs based on:\n",
        "    - Skills (TokenSet, highest weight)\n",
        "    - Title (ShortText, medium weight)\n",
        "    - Location (ShortText, lower weight)\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        # Build schema for job matching\n",
        "        builder = fr.SchemaBuilder()\n",
        "        \n",
        "        # Skills as token set (most important)\n",
        "        builder.add_field(\n",
        "            \"skills\",\n",
        "            \"token_set\",\n",
        "            weight=10,\n",
        "            separator=\",\",\n",
        "            required=True\n",
        "        )\n",
        "        \n",
        "        # Title with fuzzy matching\n",
        "        builder.add_field(\n",
        "            \"title\",\n",
        "            \"short_text\",\n",
        "            weight=5,\n",
        "            algorithm=\"jaro_winkler\",\n",
        "            normalize=\"lowercase\"\n",
        "        )\n",
        "        \n",
        "        # Location (lower weight, exact match preferred)\n",
        "        builder.add_field(\n",
        "            \"location\",\n",
        "            \"short_text\",\n",
        "            weight=2,\n",
        "            algorithm=\"jaro_winkler\",\n",
        "            normalize=\"lowercase\"\n",
        "        )\n",
        "        \n",
        "        schema = builder.build()\n",
        "        self.index = fr.SchemaIndex(schema)\n",
        "        self.candidates = {}\n",
        "    \n",
        "    def add_candidate(self, candidate: dict):\n",
        "        \"\"\"\n",
        "        Add a candidate to the index.\n",
        "        \"\"\"\n",
        "        # Normalize skills before indexing\n",
        "        normalized_skills = normalize_skills(candidate['skills'])\n",
        "        \n",
        "        record = {\n",
        "            'skills': ','.join(normalized_skills),\n",
        "            'title': candidate['title'].lower(),\n",
        "            'location': candidate['location'].lower()\n",
        "        }\n",
        "        \n",
        "        self.index.add(record, data=candidate['id'])\n",
        "        self.candidates[candidate['id']] = candidate\n",
        "    \n",
        "    def find_candidates_for_job(self, job: dict, min_score: float = 0.3, \n",
        "                                 limit: int = 10) -> list:\n",
        "        \"\"\"\n",
        "        Find candidates matching a job posting.\n",
        "        \n",
        "        Returns list of (candidate, score, field_scores) tuples.\n",
        "        \"\"\"\n",
        "        # Normalize job skills (combine required and nice-to-have)\n",
        "        all_skills = job.get('required_skills', []) + job.get('nice_to_have', [])\n",
        "        normalized_skills = normalize_skills(all_skills)\n",
        "        \n",
        "        query = {\n",
        "            'skills': ','.join(normalized_skills),\n",
        "            'title': job['title'].lower(),\n",
        "            'location': job.get('location', '').lower()\n",
        "        }\n",
        "        \n",
        "        results = self.index.search(query, min_score=min_score, limit=limit)\n",
        "        \n",
        "        # Enrich with candidate data\n",
        "        matches = []\n",
        "        for r in results:\n",
        "            candidate = self.candidates[r.data]\n",
        "            matches.append({\n",
        "                'candidate': candidate,\n",
        "                'overall_score': r.score,\n",
        "                'field_scores': r.field_scores,\n",
        "                'skill_analysis': calculate_skill_match(\n",
        "                    candidate['skills'],\n",
        "                    job.get('required_skills', []),\n",
        "                    job.get('nice_to_have', [])\n",
        "                )\n",
        "            })\n",
        "        \n",
        "        return matches\n",
        "\n",
        "\n",
        "# Build the matcher and index candidates\n",
        "talent_matcher = TalentMatcher()\n",
        "\n",
        "for candidate in CANDIDATES:\n",
        "    talent_matcher.add_candidate(candidate)\n",
        "\n",
        "print(f\"Indexed {len(talent_matcher.candidates)} candidates\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Find candidates for each job\n",
        "print(\"Talent Matching Results\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for job in JOB_POSTINGS:\n",
        "    print(f\"\\nJob: {job['title']} at {job['company']}\")\n",
        "    print(f\"Location: {job['location']}\")\n",
        "    print(f\"Required: {job['required_skills']}\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    matches = talent_matcher.find_candidates_for_job(job, min_score=0.2)\n",
        "    \n",
        "    if matches:\n",
        "        for i, m in enumerate(matches[:3], 1):  # Top 3\n",
        "            cand = m['candidate']\n",
        "            analysis = m['skill_analysis']\n",
        "            \n",
        "            print(f\"  #{i} {cand['name']} ({cand['title']})\")\n",
        "            print(f\"      Overall: {m['overall_score']:.0%} | \")\n",
        "            print(f\"      Skills: {analysis['required_match']:.0%} required, \"\n",
        "                  f\"{analysis['nice_to_have_match']:.0%} nice-to-have\")\n",
        "            if analysis['missing_required']:\n",
        "                print(f\"      Missing: {analysis['missing_required']}\")\n",
        "    else:\n",
        "        print(\"  No matching candidates found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Advanced: Fuzzy Skill Matching\n",
        "\n",
        "What if a candidate has skills that don't exactly match our taxonomy?\n",
        "\n",
        "For example:\n",
        "- \"Vue 3\" (not in taxonomy, but close to \"vue\")\n",
        "- \"FastAPI\" (might be written as \"Fast API\")\n",
        "- \"Kubernetes Administration\" (contains \"kubernetes\")\n",
        "\n",
        "We can build a fuzzy skill resolver that:\n",
        "1. First tries exact match against taxonomy\n",
        "2. Falls back to fuzzy matching if no exact match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class FuzzySkillResolver:\n",
        "    \"\"\"\n",
        "    Resolves skills using both exact taxonomy matching and fuzzy fallback.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, taxonomy: dict):\n",
        "        self.taxonomy = taxonomy\n",
        "        \n",
        "        # Build N-gram index of all skill variations\n",
        "        self.skill_index = fr.NgramIndex(ngram_size=2)\n",
        "        self.skill_to_canonical = {}\n",
        "        \n",
        "        for canonical, variations in taxonomy.items():\n",
        "            for var in variations:\n",
        "                var_lower = var.lower()\n",
        "                self.skill_index.add(var_lower)\n",
        "                self.skill_to_canonical[var_lower] = canonical\n",
        "    \n",
        "    def resolve(self, skill: str, min_similarity: float = 0.7) -> tuple:\n",
        "        \"\"\"\n",
        "        Resolve a skill to its canonical form.\n",
        "        \n",
        "        Returns: (canonical_skill, confidence, match_type)\n",
        "        \"\"\"\n",
        "        skill_lower = skill.lower().strip()\n",
        "        \n",
        "        # Try exact match first\n",
        "        if skill_lower in self.skill_to_canonical:\n",
        "            return (self.skill_to_canonical[skill_lower], 1.0, 'exact')\n",
        "        \n",
        "        # Remove common suffixes/prefixes for matching\n",
        "        cleaned = re.sub(r'\\s*(developer|engineer|programming|administration)\\s*', '', skill_lower)\n",
        "        if cleaned in self.skill_to_canonical:\n",
        "            return (self.skill_to_canonical[cleaned], 0.95, 'cleaned')\n",
        "        \n",
        "        # Fuzzy match\n",
        "        matches = self.skill_index.search(skill_lower, min_similarity=min_similarity, limit=1)\n",
        "        \n",
        "        if matches:\n",
        "            matched_var = matches[0].text\n",
        "            canonical = self.skill_to_canonical.get(matched_var, matched_var)\n",
        "            return (canonical, matches[0].score, 'fuzzy')\n",
        "        \n",
        "        # No match - return original (unknown skill)\n",
        "        return (skill_lower, 0.0, 'unknown')\n",
        "    \n",
        "    def resolve_all(self, skills: list) -> list:\n",
        "        \"\"\"\n",
        "        Resolve a list of skills.\n",
        "        \n",
        "        Returns list of (original, canonical, confidence, match_type).\n",
        "        \"\"\"\n",
        "        results = []\n",
        "        for skill in skills:\n",
        "            canonical, conf, match_type = self.resolve(skill)\n",
        "            results.append((skill, canonical, conf, match_type))\n",
        "        return results\n",
        "\n",
        "\n",
        "# Test fuzzy skill resolution\n",
        "fuzzy_resolver = FuzzySkillResolver(SKILLS_TAXONOMY)\n",
        "\n",
        "test_skills = [\n",
        "    \"React.js\",                  # Exact match\n",
        "    \"Vue 3\",                     # Should match Vue\n",
        "    \"Kubernetes Administration\", # Should match Kubernetes\n",
        "    \"Fast API\",                  # Should match FastAPI\n",
        "    \"Node Development\",          # Should match Node.js\n",
        "    \"ML Engineering\",            # Should match Machine Learning\n",
        "    \"Obscure Framework XYZ\",     # Unknown - should return as-is\n",
        "]\n",
        "\n",
        "print(\"Fuzzy Skill Resolution:\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Input':<30} {'Canonical':<20} {'Confidence':<12} {'Type'}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for skill in test_skills:\n",
        "    canonical, conf, match_type = fuzzy_resolver.resolve(skill)\n",
        "    print(f\"{skill:<30} {canonical:<20} {conf:.0%}          {match_type}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Complete Talent Matching Pipeline\n",
        "\n",
        "Let's build a production-ready pipeline that:\n",
        "\n",
        "1. Normalizes and resolves skills (with fuzzy fallback)\n",
        "2. Multi-field matching with SchemaIndex\n",
        "3. Detailed scoring breakdown\n",
        "4. Ranking with multiple factors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class TalentSearchEngine:\n",
        "    \"\"\"\n",
        "    Production-ready talent search engine.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, taxonomy: dict):\n",
        "        self.skill_resolver = FuzzySkillResolver(taxonomy)\n",
        "        self.candidates = {}\n",
        "        \n",
        "        # Build schema\n",
        "        builder = fr.SchemaBuilder()\n",
        "        builder.add_field(\"skills\", \"token_set\", weight=10, separator=\",\", required=True)\n",
        "        builder.add_field(\"title\", \"short_text\", weight=5, algorithm=\"jaro_winkler\", normalize=\"lowercase\")\n",
        "        builder.add_field(\"location\", \"short_text\", weight=2, algorithm=\"jaro_winkler\", normalize=\"lowercase\")\n",
        "        builder.add_field(\"summary\", \"long_text\", weight=3, algorithm=\"ngram\", normalize=\"lowercase\")\n",
        "        \n",
        "        schema = builder.build()\n",
        "        self.index = fr.SchemaIndex(schema)\n",
        "    \n",
        "    def _resolve_skills(self, skills: list) -> list:\n",
        "        \"\"\"Resolve skills to canonical forms.\"\"\"\n",
        "        resolved = []\n",
        "        for skill in skills:\n",
        "            canonical, conf, _ = self.skill_resolver.resolve(skill)\n",
        "            if conf > 0:  # Only include matched skills\n",
        "                resolved.append(canonical)\n",
        "            else:\n",
        "                resolved.append(skill.lower())  # Keep unknown skills\n",
        "        return list(set(resolved))\n",
        "    \n",
        "    def add_candidate(self, candidate: dict):\n",
        "        \"\"\"Add a candidate to the search index.\"\"\"\n",
        "        resolved_skills = self._resolve_skills(candidate['skills'])\n",
        "        \n",
        "        record = {\n",
        "            'skills': ','.join(resolved_skills),\n",
        "            'title': candidate['title'],\n",
        "            'location': candidate['location'],\n",
        "            'summary': candidate.get('summary', '')\n",
        "        }\n",
        "        \n",
        "        self.index.add(record, data=candidate['id'])\n",
        "        self.candidates[candidate['id']] = {\n",
        "            **candidate,\n",
        "            'resolved_skills': resolved_skills\n",
        "        }\n",
        "    \n",
        "    def search(self, job: dict, min_score: float = 0.2, limit: int = 10) -> list:\n",
        "        \"\"\"\n",
        "        Search for candidates matching a job.\n",
        "        \n",
        "        Returns detailed match results with breakdown.\n",
        "        \"\"\"\n",
        "        # Resolve job skills\n",
        "        required = self._resolve_skills(job.get('required_skills', []))\n",
        "        nice_to_have = self._resolve_skills(job.get('nice_to_have', []))\n",
        "        all_skills = list(set(required + nice_to_have))\n",
        "        \n",
        "        query = {\n",
        "            'skills': ','.join(all_skills),\n",
        "            'title': job['title'],\n",
        "            'location': job.get('location', ''),\n",
        "            'summary': job.get('description', '')\n",
        "        }\n",
        "        \n",
        "        results = self.index.search(query, min_score=min_score, limit=limit)\n",
        "        \n",
        "        matches = []\n",
        "        for r in results:\n",
        "            candidate = self.candidates[r.data]\n",
        "            \n",
        "            # Detailed skill analysis\n",
        "            cand_skills = set(candidate['resolved_skills'])\n",
        "            req_skills = set(required)\n",
        "            nice_skills = set(nice_to_have)\n",
        "            \n",
        "            matched_required = cand_skills & req_skills\n",
        "            matched_nice = cand_skills & nice_skills\n",
        "            missing_required = req_skills - cand_skills\n",
        "            \n",
        "            # Experience match\n",
        "            cand_exp = candidate.get('experience_years', 0)\n",
        "            req_exp = job.get('experience_years', 0)\n",
        "            exp_match = min(cand_exp / req_exp, 1.0) if req_exp > 0 else 1.0\n",
        "            \n",
        "            matches.append({\n",
        "                'candidate': candidate,\n",
        "                'overall_score': r.score,\n",
        "                'field_scores': r.field_scores,\n",
        "                'skills': {\n",
        "                    'required_match': len(matched_required) / len(req_skills) if req_skills else 1.0,\n",
        "                    'nice_to_have_match': len(matched_nice) / len(nice_skills) if nice_skills else 0,\n",
        "                    'matched_required': sorted(matched_required),\n",
        "                    'matched_nice_to_have': sorted(matched_nice),\n",
        "                    'missing_required': sorted(missing_required)\n",
        "                },\n",
        "                'experience_match': exp_match,\n",
        "                'recommendation': self._get_recommendation(r.score, len(matched_required), len(req_skills))\n",
        "            })\n",
        "        \n",
        "        # Sort by overall score (already sorted, but explicit)\n",
        "        matches.sort(key=lambda x: -x['overall_score'])\n",
        "        \n",
        "        return matches\n",
        "    \n",
        "    def _get_recommendation(self, score: float, matched: int, required: int) -> str:\n",
        "        \"\"\"Generate a hiring recommendation.\"\"\"\n",
        "        skill_pct = matched / required if required > 0 else 1.0\n",
        "        \n",
        "        if score >= 0.8 and skill_pct >= 0.8:\n",
        "            return \"STRONG MATCH - Recommend interview\"\n",
        "        elif score >= 0.6 and skill_pct >= 0.6:\n",
        "            return \"GOOD MATCH - Consider for interview\"\n",
        "        elif score >= 0.4 and skill_pct >= 0.5:\n",
        "            return \"PARTIAL MATCH - Review manually\"\n",
        "        else:\n",
        "            return \"WEAK MATCH - May not be suitable\"\n",
        "\n",
        "\n",
        "# Initialize and populate\n",
        "search_engine = TalentSearchEngine(SKILLS_TAXONOMY)\n",
        "\n",
        "for candidate in CANDIDATES:\n",
        "    search_engine.add_candidate(candidate)\n",
        "\n",
        "print(f\"Talent Search Engine initialized with {len(search_engine.candidates)} candidates\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demo the search engine\n",
        "job = JOB_POSTINGS[0]  # Senior Full Stack Developer\n",
        "\n",
        "print(f\"\\nSearching candidates for: {job['title']} at {job['company']}\")\n",
        "print(f\"Location: {job['location']}\")\n",
        "print(f\"Required Skills: {job['required_skills']}\")\n",
        "print(f\"Nice-to-Have: {job['nice_to_have']}\")\n",
        "print(f\"Experience Required: {job['experience_years']}+ years\")\n",
        "print(\"\\n\" + \"=\" * 70)\n",
        "\n",
        "matches = search_engine.search(job)\n",
        "\n",
        "for i, m in enumerate(matches, 1):\n",
        "    cand = m['candidate']\n",
        "    skills = m['skills']\n",
        "    \n",
        "    print(f\"\\n#{i} {cand['name']}\")\n",
        "    print(f\"   Title: {cand['title']}\")\n",
        "    print(f\"   Location: {cand['location']}\")\n",
        "    print(f\"   Experience: {cand['experience_years']} years\")\n",
        "    print(f\"   \")\n",
        "    print(f\"   Overall Score: {m['overall_score']:.0%}\")\n",
        "    print(f\"   Required Skills: {skills['required_match']:.0%} ({len(skills['matched_required'])}/{len(skills['matched_required']) + len(skills['missing_required'])})\")\n",
        "    print(f\"   Nice-to-Have: {skills['nice_to_have_match']:.0%}\")\n",
        "    print(f\"   Experience Match: {m['experience_match']:.0%}\")\n",
        "    print(f\"   \")\n",
        "    if skills['missing_required']:\n",
        "        print(f\"   Missing Required: {skills['missing_required']}\")\n",
        "    print(f\"   \")\n",
        "    print(f\"   >> {m['recommendation']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Batch Processing: Matching Many Jobs to Many Candidates\n",
        "\n",
        "In production, you often need to:\n",
        "- Find best candidates for multiple jobs\n",
        "- Find best jobs for a single candidate\n",
        "- Generate match reports\n",
        "\n",
        "Let's build utilities for these scenarios."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_match_report(search_engine: TalentSearchEngine, jobs: list) -> dict:\n",
        "    \"\"\"\n",
        "    Generate a comprehensive match report for multiple jobs.\n",
        "    \"\"\"\n",
        "    report = {\n",
        "        'jobs_analyzed': len(jobs),\n",
        "        'candidates_in_pool': len(search_engine.candidates),\n",
        "        'job_matches': []\n",
        "    }\n",
        "    \n",
        "    for job in jobs:\n",
        "        matches = search_engine.search(job, min_score=0.3, limit=5)\n",
        "        \n",
        "        strong = [m for m in matches if 'STRONG' in m['recommendation']]\n",
        "        good = [m for m in matches if 'GOOD' in m['recommendation']]\n",
        "        partial = [m for m in matches if 'PARTIAL' in m['recommendation']]\n",
        "        \n",
        "        report['job_matches'].append({\n",
        "            'job_id': job['id'],\n",
        "            'job_title': job['title'],\n",
        "            'company': job['company'],\n",
        "            'total_matches': len(matches),\n",
        "            'strong_matches': len(strong),\n",
        "            'good_matches': len(good),\n",
        "            'partial_matches': len(partial),\n",
        "            'top_candidate': matches[0]['candidate']['name'] if matches else None,\n",
        "            'top_score': matches[0]['overall_score'] if matches else 0\n",
        "        })\n",
        "    \n",
        "    return report\n",
        "\n",
        "\n",
        "# Generate report\n",
        "report = generate_match_report(search_engine, JOB_POSTINGS)\n",
        "\n",
        "print(\"Talent Match Report\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"Jobs Analyzed: {report['jobs_analyzed']}\")\n",
        "print(f\"Candidate Pool: {report['candidates_in_pool']}\")\n",
        "print()\n",
        "\n",
        "print(f\"{'Job':<30} {'Strong':<8} {'Good':<8} {'Top Candidate':<20} {'Score'}\")\n",
        "print(\"-\" * 75)\n",
        "\n",
        "for jm in report['job_matches']:\n",
        "    print(f\"{jm['job_title']:<30} {jm['strong_matches']:<8} {jm['good_matches']:<8} \"\n",
        "          f\"{jm['top_candidate'] or 'None':<20} {jm['top_score']:.0%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Production Considerations\n",
        "\n",
        "### Performance\n",
        "\n",
        "| Candidate Pool Size | Expected Search Time | Recommendation |\n",
        "|---------------------|---------------------|----------------|\n",
        "| <1,000 | <10ms | SchemaIndex sufficient |\n",
        "| 1,000-10,000 | 10-50ms | Add skill pre-filtering |\n",
        "| 10,000-100,000 | 50-200ms | Use blocking by required skills |\n",
        "| >100,000 | Use database | PostgreSQL + fuzzy + application filtering |\n",
        "\n",
        "### Skill Taxonomy Maintenance\n",
        "\n",
        "Your taxonomy will need updates as:\n",
        "- New technologies emerge (\"Bun\", \"Astro\", etc.)\n",
        "- Terms evolve (\"Data Science\" → \"ML Engineering\")\n",
        "- Industry-specific variations appear\n",
        "\n",
        "Consider:\n",
        "- Automated alias detection from job posting text\n",
        "- Periodic review of \"unknown\" skills\n",
        "- Integration with external taxonomies (O*NET, ESCO)\n",
        "\n",
        "### Bias Considerations\n",
        "\n",
        "Automated resume screening can encode bias:\n",
        "- Favor candidates with \"standard\" skill naming (disadvantages non-native speakers)\n",
        "- Weight prestigious company names in summaries\n",
        "- Geographic bias from location matching\n",
        "\n",
        "Mitigations:\n",
        "- Focus matching on skills, not text style\n",
        "- Remove or de-weight company names\n",
        "- Support remote work fairly\n",
        "- Regular audits of match demographics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this guide, we built a complete talent matching system:\n",
        "\n",
        "1. **Skills Taxonomy**: Canonical forms + aliases for consistent matching\n",
        "2. **Fuzzy Skill Resolution**: Handle unknown skills gracefully\n",
        "3. **Multi-Field Matching**: SchemaIndex for title + skills + location + description\n",
        "4. **Weighted Scoring**: Required skills weighted higher than nice-to-have\n",
        "5. **Hiring Recommendations**: Automated categorization of match quality\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "- **TokenSet** field type is ideal for skill list comparison (Jaccard similarity)\n",
        "- **Skill normalization** is critical - \"React.js\" and \"ReactJS\" must match\n",
        "- **Fuzzy resolution** handles unknown variations gracefully\n",
        "- **Multi-field matching** considers the whole candidate, not just skills\n",
        "- **Weighted scoring** lets you prioritize what matters most\n",
        "\n",
        "### When to Use This Approach\n",
        "\n",
        "- ATS (Applicant Tracking System) resume filtering\n",
        "- Internal talent mobility / skill matching\n",
        "- Freelancer / contractor matching platforms\n",
        "- Training recommendation systems\n",
        "- Team composition optimization"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
