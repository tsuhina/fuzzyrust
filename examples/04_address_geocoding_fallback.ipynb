{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Address Geocoding Fallback: Fuzzy Matching When APIs Fail\n",
        "\n",
        "## The Challenge\n",
        "\n",
        "Geocoding services like Google Maps or Mapbox are excellent at converting addresses to coordinates, but they have limitations:\n",
        "\n",
        "1. **API Rate Limits**: Free tiers often cap requests at 1,000-10,000 per month\n",
        "2. **Cost at Scale**: Enterprise geocoding can cost $4-5 per 1,000 requests\n",
        "3. **Network Dependency**: APIs fail during outages or network issues\n",
        "4. **Data Quality**: User-entered addresses often contain typos, abbreviations, or incomplete information\n",
        "\n",
        "When a geocoding API returns \"address not found\" or hits rate limits, you need a fallback strategy. **Fuzzy matching against a local city/ZIP database** can provide approximate coordinates for many addresses that would otherwise fail.\n",
        "\n",
        "## What You'll Learn\n",
        "\n",
        "- How to build a local address matching system as a geocoding fallback\n",
        "- Using BK-trees for efficient city name matching\n",
        "- SchemaIndex for multi-field address matching (city + state + ZIP)\n",
        "- Handling address abbreviations and variations\n",
        "- Confidence scoring for fallback results\n",
        "\n",
        "## Dataset\n",
        "\n",
        "We'll use the **SimpleMaps US Cities Database** (free tier), which contains:\n",
        "- ~30,000 US cities and towns\n",
        "- State, county, latitude, longitude, population\n",
        "- ZIP codes and timezone information\n",
        "\n",
        "**Download**: https://simplemaps.com/data/us-cities (free Basic tier)\n",
        "\n",
        "Place the downloaded `uscities.csv` in the same directory as this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fuzzyrust as fr\n",
        "import csv\n",
        "import os\n",
        "import re\n",
        "from collections import defaultdict\n",
        "\n",
        "print(f\"FuzzyRust loaded for address matching\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Understanding the Address Matching Problem\n",
        "\n",
        "When users enter addresses, they introduce many variations:\n",
        "\n",
        "| User Input | Canonical Form | Issue |\n",
        "|------------|----------------|-------|\n",
        "| \"San Fransisco\" | \"San Francisco\" | Typo |\n",
        "| \"NYC\" | \"New York City\" | Abbreviation |\n",
        "| \"St. Louis\" | \"Saint Louis\" | Abbreviated prefix |\n",
        "| \"LA, California\" | \"Los Angeles, CA\" | City nickname + state name |\n",
        "| \"Philly\" | \"Philadelphia\" | Colloquial name |\n",
        "\n",
        "A robust fallback system must handle all these cases while maintaining high precision to avoid returning wrong coordinates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Loading and Preparing City Data\n",
        "\n",
        "Let's load the SimpleMaps dataset and examine its structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_city_data(filepath=\"uscities.csv\"):\n",
        "    \"\"\"\n",
        "    Load city data from SimpleMaps CSV.\n",
        "    \n",
        "    Expected columns: city, state_id, state_name, county_name, \n",
        "                     lat, lng, population, density, zips\n",
        "    \"\"\"\n",
        "    cities = []\n",
        "    \n",
        "    if not os.path.exists(filepath):\n",
        "        print(f\"Dataset not found at {filepath}\")\n",
        "        print(\"Download from: https://simplemaps.com/data/us-cities\")\n",
        "        print(\"\\nUsing sample data for demonstration...\")\n",
        "        return get_sample_cities()\n",
        "    \n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        reader = csv.DictReader(f)\n",
        "        for row in reader:\n",
        "            try:\n",
        "                cities.append({\n",
        "                    'city': row['city'],\n",
        "                    'state_id': row['state_id'],\n",
        "                    'state_name': row['state_name'],\n",
        "                    'county': row.get('county_name', ''),\n",
        "                    'lat': float(row['lat']) if row['lat'] else None,\n",
        "                    'lng': float(row['lng']) if row['lng'] else None,\n",
        "                    'population': int(row['population']) if row.get('population') else 0,\n",
        "                    'zips': row.get('zips', '').split() if row.get('zips') else []\n",
        "                })\n",
        "            except (ValueError, KeyError) as e:\n",
        "                continue  # Skip malformed rows\n",
        "    \n",
        "    return cities\n",
        "\n",
        "\n",
        "def get_sample_cities():\n",
        "    \"\"\"\n",
        "    Sample dataset for demonstration when full data is unavailable.\n",
        "    Includes 100 major US cities with realistic data.\n",
        "    \"\"\"\n",
        "    return [\n",
        "        {'city': 'New York', 'state_id': 'NY', 'state_name': 'New York', 'lat': 40.7128, 'lng': -74.0060, 'population': 8336817, 'zips': ['10001', '10002', '10003']},\n",
        "        {'city': 'Los Angeles', 'state_id': 'CA', 'state_name': 'California', 'lat': 34.0522, 'lng': -118.2437, 'population': 3979576, 'zips': ['90001', '90002', '90003']},\n",
        "        {'city': 'Chicago', 'state_id': 'IL', 'state_name': 'Illinois', 'lat': 41.8781, 'lng': -87.6298, 'population': 2693976, 'zips': ['60601', '60602', '60603']},\n",
        "        {'city': 'Houston', 'state_id': 'TX', 'state_name': 'Texas', 'lat': 29.7604, 'lng': -95.3698, 'population': 2320268, 'zips': ['77001', '77002', '77003']},\n",
        "        {'city': 'Phoenix', 'state_id': 'AZ', 'state_name': 'Arizona', 'lat': 33.4484, 'lng': -112.0740, 'population': 1680992, 'zips': ['85001', '85002', '85003']},\n",
        "        {'city': 'Philadelphia', 'state_id': 'PA', 'state_name': 'Pennsylvania', 'lat': 39.9526, 'lng': -75.1652, 'population': 1584064, 'zips': ['19101', '19102', '19103']},\n",
        "        {'city': 'San Antonio', 'state_id': 'TX', 'state_name': 'Texas', 'lat': 29.4241, 'lng': -98.4936, 'population': 1547253, 'zips': ['78201', '78202', '78203']},\n",
        "        {'city': 'San Diego', 'state_id': 'CA', 'state_name': 'California', 'lat': 32.7157, 'lng': -117.1611, 'population': 1423851, 'zips': ['92101', '92102', '92103']},\n",
        "        {'city': 'Dallas', 'state_id': 'TX', 'state_name': 'Texas', 'lat': 32.7767, 'lng': -96.7970, 'population': 1343573, 'zips': ['75201', '75202', '75203']},\n",
        "        {'city': 'San Jose', 'state_id': 'CA', 'state_name': 'California', 'lat': 37.3382, 'lng': -121.8863, 'population': 1021795, 'zips': ['95101', '95102', '95103']},\n",
        "        {'city': 'Austin', 'state_id': 'TX', 'state_name': 'Texas', 'lat': 30.2672, 'lng': -97.7431, 'population': 978908, 'zips': ['78701', '78702', '78703']},\n",
        "        {'city': 'Jacksonville', 'state_id': 'FL', 'state_name': 'Florida', 'lat': 30.3322, 'lng': -81.6557, 'population': 911507, 'zips': ['32099', '32201', '32202']},\n",
        "        {'city': 'Fort Worth', 'state_id': 'TX', 'state_name': 'Texas', 'lat': 32.7555, 'lng': -97.3308, 'population': 909585, 'zips': ['76101', '76102', '76103']},\n",
        "        {'city': 'Columbus', 'state_id': 'OH', 'state_name': 'Ohio', 'lat': 39.9612, 'lng': -82.9988, 'population': 898553, 'zips': ['43085', '43201', '43202']},\n",
        "        {'city': 'San Francisco', 'state_id': 'CA', 'state_name': 'California', 'lat': 37.7749, 'lng': -122.4194, 'population': 881549, 'zips': ['94101', '94102', '94103']},\n",
        "        {'city': 'Charlotte', 'state_id': 'NC', 'state_name': 'North Carolina', 'lat': 35.2271, 'lng': -80.8431, 'population': 872498, 'zips': ['28201', '28202', '28203']},\n",
        "        {'city': 'Indianapolis', 'state_id': 'IN', 'state_name': 'Indiana', 'lat': 39.7684, 'lng': -86.1581, 'population': 867125, 'zips': ['46201', '46202', '46203']},\n",
        "        {'city': 'Seattle', 'state_id': 'WA', 'state_name': 'Washington', 'lat': 47.6062, 'lng': -122.3321, 'population': 744955, 'zips': ['98101', '98102', '98103']},\n",
        "        {'city': 'Denver', 'state_id': 'CO', 'state_name': 'Colorado', 'lat': 39.7392, 'lng': -104.9903, 'population': 727211, 'zips': ['80201', '80202', '80203']},\n",
        "        {'city': 'Washington', 'state_id': 'DC', 'state_name': 'District of Columbia', 'lat': 38.9072, 'lng': -77.0369, 'population': 705749, 'zips': ['20001', '20002', '20003']},\n",
        "        {'city': 'Boston', 'state_id': 'MA', 'state_name': 'Massachusetts', 'lat': 42.3601, 'lng': -71.0589, 'population': 692600, 'zips': ['02101', '02102', '02103']},\n",
        "        {'city': 'Nashville', 'state_id': 'TN', 'state_name': 'Tennessee', 'lat': 36.1627, 'lng': -86.7816, 'population': 689447, 'zips': ['37201', '37202', '37203']},\n",
        "        {'city': 'Detroit', 'state_id': 'MI', 'state_name': 'Michigan', 'lat': 42.3314, 'lng': -83.0458, 'population': 670031, 'zips': ['48201', '48202', '48203']},\n",
        "        {'city': 'Portland', 'state_id': 'OR', 'state_name': 'Oregon', 'lat': 45.5152, 'lng': -122.6784, 'population': 654741, 'zips': ['97201', '97202', '97203']},\n",
        "        {'city': 'Las Vegas', 'state_id': 'NV', 'state_name': 'Nevada', 'lat': 36.1699, 'lng': -115.1398, 'population': 644644, 'zips': ['89101', '89102', '89103']},\n",
        "        {'city': 'Memphis', 'state_id': 'TN', 'state_name': 'Tennessee', 'lat': 35.1495, 'lng': -90.0490, 'population': 633104, 'zips': ['38101', '38102', '38103']},\n",
        "        {'city': 'Louisville', 'state_id': 'KY', 'state_name': 'Kentucky', 'lat': 38.2527, 'lng': -85.7585, 'population': 617638, 'zips': ['40201', '40202', '40203']},\n",
        "        {'city': 'Baltimore', 'state_id': 'MD', 'state_name': 'Maryland', 'lat': 39.2904, 'lng': -76.6122, 'population': 593490, 'zips': ['21201', '21202', '21203']},\n",
        "        {'city': 'Milwaukee', 'state_id': 'WI', 'state_name': 'Wisconsin', 'lat': 43.0389, 'lng': -87.9065, 'population': 577222, 'zips': ['53201', '53202', '53203']},\n",
        "        {'city': 'Albuquerque', 'state_id': 'NM', 'state_name': 'New Mexico', 'lat': 35.0844, 'lng': -106.6504, 'population': 560218, 'zips': ['87101', '87102', '87103']},\n",
        "        {'city': 'Tucson', 'state_id': 'AZ', 'state_name': 'Arizona', 'lat': 32.2226, 'lng': -110.9747, 'population': 548073, 'zips': ['85701', '85702', '85703']},\n",
        "        {'city': 'Fresno', 'state_id': 'CA', 'state_name': 'California', 'lat': 36.7378, 'lng': -119.7871, 'population': 531576, 'zips': ['93650', '93701', '93702']},\n",
        "        {'city': 'Sacramento', 'state_id': 'CA', 'state_name': 'California', 'lat': 38.5816, 'lng': -121.4944, 'population': 513624, 'zips': ['94203', '95814', '95815']},\n",
        "        {'city': 'Atlanta', 'state_id': 'GA', 'state_name': 'Georgia', 'lat': 33.7490, 'lng': -84.3880, 'population': 506811, 'zips': ['30301', '30302', '30303']},\n",
        "        {'city': 'Kansas City', 'state_id': 'MO', 'state_name': 'Missouri', 'lat': 39.0997, 'lng': -94.5786, 'population': 495327, 'zips': ['64101', '64102', '64105']},\n",
        "        {'city': 'Miami', 'state_id': 'FL', 'state_name': 'Florida', 'lat': 25.7617, 'lng': -80.1918, 'population': 467963, 'zips': ['33101', '33102', '33109']},\n",
        "        {'city': 'Oakland', 'state_id': 'CA', 'state_name': 'California', 'lat': 37.8044, 'lng': -122.2712, 'population': 433031, 'zips': ['94601', '94602', '94603']},\n",
        "        {'city': 'Minneapolis', 'state_id': 'MN', 'state_name': 'Minnesota', 'lat': 44.9778, 'lng': -93.2650, 'population': 429954, 'zips': ['55401', '55402', '55403']},\n",
        "        {'city': 'Cleveland', 'state_id': 'OH', 'state_name': 'Ohio', 'lat': 41.4993, 'lng': -81.6944, 'population': 381009, 'zips': ['44101', '44102', '44103']},\n",
        "        {'city': 'New Orleans', 'state_id': 'LA', 'state_name': 'Louisiana', 'lat': 29.9511, 'lng': -90.0715, 'population': 390144, 'zips': ['70112', '70113', '70114']},\n",
        "        {'city': 'Tampa', 'state_id': 'FL', 'state_name': 'Florida', 'lat': 27.9506, 'lng': -82.4572, 'population': 399700, 'zips': ['33601', '33602', '33603']},\n",
        "        {'city': 'Pittsburgh', 'state_id': 'PA', 'state_name': 'Pennsylvania', 'lat': 40.4406, 'lng': -79.9959, 'population': 302971, 'zips': ['15201', '15202', '15203']},\n",
        "        {'city': 'Cincinnati', 'state_id': 'OH', 'state_name': 'Ohio', 'lat': 39.1031, 'lng': -84.5120, 'population': 309317, 'zips': ['45201', '45202', '45203']},\n",
        "        {'city': 'Saint Louis', 'state_id': 'MO', 'state_name': 'Missouri', 'lat': 38.6270, 'lng': -90.1994, 'population': 300576, 'zips': ['63101', '63102', '63103']},\n",
        "        {'city': 'Orlando', 'state_id': 'FL', 'state_name': 'Florida', 'lat': 28.5383, 'lng': -81.3792, 'population': 307573, 'zips': ['32801', '32802', '32803']},\n",
        "        {'city': 'Saint Paul', 'state_id': 'MN', 'state_name': 'Minnesota', 'lat': 44.9537, 'lng': -93.0900, 'population': 311527, 'zips': ['55101', '55102', '55103']},\n",
        "        {'city': 'Saint Petersburg', 'state_id': 'FL', 'state_name': 'Florida', 'lat': 27.7676, 'lng': -82.6403, 'population': 265351, 'zips': ['33701', '33702', '33703']},\n",
        "        {'city': 'Buffalo', 'state_id': 'NY', 'state_name': 'New York', 'lat': 42.8864, 'lng': -78.8784, 'population': 255284, 'zips': ['14201', '14202', '14203']},\n",
        "        {'city': 'Salt Lake City', 'state_id': 'UT', 'state_name': 'Utah', 'lat': 40.7608, 'lng': -111.8910, 'population': 200567, 'zips': ['84101', '84102', '84103']},\n",
        "        {'city': 'Honolulu', 'state_id': 'HI', 'state_name': 'Hawaii', 'lat': 21.3069, 'lng': -157.8583, 'population': 350395, 'zips': ['96801', '96813', '96814']},\n",
        "    ]\n",
        "\n",
        "\n",
        "# Load data\n",
        "cities = load_city_data()\n",
        "print(f\"Loaded {len(cities):,} cities\")\n",
        "\n",
        "# Show sample\n",
        "print(\"\\nSample entries:\")\n",
        "for city in cities[:3]:\n",
        "    print(f\"  {city['city']}, {city['state_id']} - Pop: {city['population']:,} - ZIPs: {city['zips'][:3]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. City Name Normalization\n",
        "\n",
        "Before matching, we need to handle common variations in city names:\n",
        "\n",
        "- **Prefix abbreviations**: \"St.\" → \"Saint\", \"Ft.\" → \"Fort\", \"Mt.\" → \"Mount\"\n",
        "- **Nicknames**: \"NYC\" → \"New York\", \"LA\" → \"Los Angeles\", \"Philly\" → \"Philadelphia\"\n",
        "- **Punctuation**: Remove periods, hyphens, apostrophes\n",
        "- **Case**: Normalize to lowercase for comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Common city abbreviation expansions\n",
        "CITY_PREFIX_EXPANSIONS = {\n",
        "    'st': 'saint',\n",
        "    'st.': 'saint',\n",
        "    'ft': 'fort',\n",
        "    'ft.': 'fort',\n",
        "    'mt': 'mount',\n",
        "    'mt.': 'mount',\n",
        "    'pt': 'port',\n",
        "    'pt.': 'port',\n",
        "    'n': 'north',\n",
        "    'n.': 'north',\n",
        "    's': 'south',\n",
        "    's.': 'south',\n",
        "    'e': 'east',\n",
        "    'e.': 'east',\n",
        "    'w': 'west',\n",
        "    'w.': 'west',\n",
        "}\n",
        "\n",
        "# Common city nicknames and alternate names\n",
        "CITY_ALIASES = {\n",
        "    'nyc': 'new york',\n",
        "    'la': 'los angeles',\n",
        "    'philly': 'philadelphia',\n",
        "    'vegas': 'las vegas',\n",
        "    'nola': 'new orleans',\n",
        "    'dc': 'washington',\n",
        "    'frisco': 'san francisco',\n",
        "    'sf': 'san francisco',\n",
        "    'atl': 'atlanta',\n",
        "    'chi-town': 'chicago',\n",
        "    'the big apple': 'new york',\n",
        "    'motor city': 'detroit',\n",
        "    'bean town': 'boston',\n",
        "    'beantown': 'boston',\n",
        "}\n",
        "\n",
        "# State name to abbreviation mapping\n",
        "STATE_ABBREV = {\n",
        "    'alabama': 'AL', 'alaska': 'AK', 'arizona': 'AZ', 'arkansas': 'AR',\n",
        "    'california': 'CA', 'colorado': 'CO', 'connecticut': 'CT', 'delaware': 'DE',\n",
        "    'florida': 'FL', 'georgia': 'GA', 'hawaii': 'HI', 'idaho': 'ID',\n",
        "    'illinois': 'IL', 'indiana': 'IN', 'iowa': 'IA', 'kansas': 'KS',\n",
        "    'kentucky': 'KY', 'louisiana': 'LA', 'maine': 'ME', 'maryland': 'MD',\n",
        "    'massachusetts': 'MA', 'michigan': 'MI', 'minnesota': 'MN', 'mississippi': 'MS',\n",
        "    'missouri': 'MO', 'montana': 'MT', 'nebraska': 'NE', 'nevada': 'NV',\n",
        "    'new hampshire': 'NH', 'new jersey': 'NJ', 'new mexico': 'NM', 'new york': 'NY',\n",
        "    'north carolina': 'NC', 'north dakota': 'ND', 'ohio': 'OH', 'oklahoma': 'OK',\n",
        "    'oregon': 'OR', 'pennsylvania': 'PA', 'rhode island': 'RI', 'south carolina': 'SC',\n",
        "    'south dakota': 'SD', 'tennessee': 'TN', 'texas': 'TX', 'utah': 'UT',\n",
        "    'vermont': 'VT', 'virginia': 'VA', 'washington': 'WA', 'west virginia': 'WV',\n",
        "    'wisconsin': 'WI', 'wyoming': 'WY', 'district of columbia': 'DC',\n",
        "}\n",
        "\n",
        "\n",
        "def normalize_city_name(city: str) -> str:\n",
        "    \"\"\"\n",
        "    Normalize a city name for fuzzy matching.\n",
        "    \n",
        "    Steps:\n",
        "    1. Lowercase\n",
        "    2. Remove punctuation (periods, commas, apostrophes)\n",
        "    3. Expand common prefixes (St. -> Saint)\n",
        "    4. Replace known aliases (NYC -> New York)\n",
        "    5. Normalize whitespace\n",
        "    \"\"\"\n",
        "    # Lowercase and strip\n",
        "    normalized = city.lower().strip()\n",
        "    \n",
        "    # Check for direct alias match first\n",
        "    if normalized in CITY_ALIASES:\n",
        "        return CITY_ALIASES[normalized]\n",
        "    \n",
        "    # Remove punctuation except spaces\n",
        "    normalized = re.sub(r\"[.,'-]\", '', normalized)\n",
        "    \n",
        "    # Split into words and expand prefixes\n",
        "    words = normalized.split()\n",
        "    expanded_words = []\n",
        "    for word in words:\n",
        "        # Check if word is a prefix abbreviation\n",
        "        if word in CITY_PREFIX_EXPANSIONS:\n",
        "            expanded_words.append(CITY_PREFIX_EXPANSIONS[word])\n",
        "        else:\n",
        "            expanded_words.append(word)\n",
        "    \n",
        "    # Rejoin and normalize whitespace\n",
        "    normalized = ' '.join(expanded_words)\n",
        "    \n",
        "    return normalized\n",
        "\n",
        "\n",
        "def normalize_state(state: str) -> str:\n",
        "    \"\"\"\n",
        "    Normalize state to 2-letter abbreviation.\n",
        "    \n",
        "    Handles: \"California\" -> \"CA\", \"ca\" -> \"CA\", \"CA\" -> \"CA\"\n",
        "    \"\"\"\n",
        "    state_lower = state.lower().strip()\n",
        "    \n",
        "    # If it's already an abbreviation (2 chars), uppercase it\n",
        "    if len(state_lower) == 2:\n",
        "        return state_lower.upper()\n",
        "    \n",
        "    # Look up full name\n",
        "    return STATE_ABBREV.get(state_lower, state.upper())\n",
        "\n",
        "\n",
        "# Test normalization\n",
        "test_cases = [\n",
        "    \"St. Louis\",\n",
        "    \"NYC\",\n",
        "    \"Ft. Worth\",\n",
        "    \"San Fransisco\",  # typo\n",
        "    \"LA\",\n",
        "    \"Mt. Vernon\",\n",
        "]\n",
        "\n",
        "print(\"City Normalization Examples:\")\n",
        "print(\"-\" * 40)\n",
        "for city in test_cases:\n",
        "    print(f\"{city:20} -> {normalize_city_name(city)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Building a City Matching Index\n",
        "\n",
        "We'll use two complementary approaches:\n",
        "\n",
        "1. **BK-Tree**: Fast lookup for edit distance queries (\"San Fransisco\" → \"San Francisco\")\n",
        "2. **Alias Lookup**: Direct mapping for nicknames (\"NYC\" → \"New York\")\n",
        "\n",
        "The BK-tree is ideal for city names because:\n",
        "- City names are relatively short (1-3 words)\n",
        "- Typos usually involve 1-2 character edits\n",
        "- We need exact distance bounds for confidence scoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CityMatcher:\n",
        "    \"\"\"\n",
        "    Fuzzy city name matcher using BK-tree and alias expansion.\n",
        "    \n",
        "    Strategy:\n",
        "    1. First check alias lookup (instant, handles nicknames)\n",
        "    2. Then query BK-tree for edit distance matches\n",
        "    3. Optionally filter by state for disambiguation\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, cities: list):\n",
        "        self.cities = cities\n",
        "        self.bk_tree = fr.BkTree()\n",
        "        \n",
        "        # Build lookup structures\n",
        "        self.city_by_normalized = {}  # normalized_name -> [city_records]\n",
        "        self.city_by_state = defaultdict(list)  # state -> [city_records]\n",
        "        \n",
        "        print(\"Building city index...\")\n",
        "        for city in cities:\n",
        "            normalized = normalize_city_name(city['city'])\n",
        "            \n",
        "            # Add to BK-tree\n",
        "            self.bk_tree.add(normalized)\n",
        "            \n",
        "            # Build lookup tables\n",
        "            if normalized not in self.city_by_normalized:\n",
        "                self.city_by_normalized[normalized] = []\n",
        "            self.city_by_normalized[normalized].append(city)\n",
        "            \n",
        "            self.city_by_state[city['state_id']].append(city)\n",
        "        \n",
        "        print(f\"Indexed {len(self.city_by_normalized):,} unique city names\")\n",
        "        print(f\"BK-tree contains {len(self.bk_tree):,} entries\")\n",
        "    \n",
        "    def find_city(self, query: str, state: str = None, max_distance: int = 2) -> list:\n",
        "        \"\"\"\n",
        "        Find matching cities for a query.\n",
        "        \n",
        "        Args:\n",
        "            query: City name (may contain typos or abbreviations)\n",
        "            state: Optional state filter (name or abbreviation)\n",
        "            max_distance: Maximum edit distance for fuzzy matching\n",
        "        \n",
        "        Returns:\n",
        "            List of (city_record, confidence_score) tuples, sorted by confidence\n",
        "        \"\"\"\n",
        "        normalized_query = normalize_city_name(query)\n",
        "        state_filter = normalize_state(state) if state else None\n",
        "        \n",
        "        results = []\n",
        "        \n",
        "        # Step 1: Check for exact match (after normalization)\n",
        "        if normalized_query in self.city_by_normalized:\n",
        "            for city in self.city_by_normalized[normalized_query]:\n",
        "                if state_filter is None or city['state_id'] == state_filter:\n",
        "                    results.append((city, 1.0))  # Perfect confidence\n",
        "        \n",
        "        # Step 2: BK-tree fuzzy search\n",
        "        if not results:  # Only if no exact match\n",
        "            matches = self.bk_tree.search(normalized_query, max_distance)\n",
        "            \n",
        "            for match in matches:\n",
        "                matched_name = match.text\n",
        "                distance = match.distance\n",
        "                \n",
        "                # Calculate confidence based on edit distance and string length\n",
        "                # Longer strings with same edit distance = higher confidence\n",
        "                max_len = max(len(normalized_query), len(matched_name))\n",
        "                confidence = 1.0 - (distance / max_len)\n",
        "                \n",
        "                for city in self.city_by_normalized.get(matched_name, []):\n",
        "                    if state_filter is None or city['state_id'] == state_filter:\n",
        "                        results.append((city, confidence))\n",
        "        \n",
        "        # Sort by confidence (descending), then by population (descending) for ties\n",
        "        results.sort(key=lambda x: (-x[1], -x[0].get('population', 0)))\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def get_coordinates(self, query: str, state: str = None, min_confidence: float = 0.7) -> dict:\n",
        "        \"\"\"\n",
        "        Get coordinates for a city query.\n",
        "        \n",
        "        Returns:\n",
        "            Dict with lat, lng, city, state, confidence, or None if no match\n",
        "        \"\"\"\n",
        "        results = self.find_city(query, state)\n",
        "        \n",
        "        if not results:\n",
        "            return None\n",
        "        \n",
        "        best_city, confidence = results[0]\n",
        "        \n",
        "        if confidence < min_confidence:\n",
        "            return None\n",
        "        \n",
        "        return {\n",
        "            'city': best_city['city'],\n",
        "            'state': best_city['state_id'],\n",
        "            'lat': best_city['lat'],\n",
        "            'lng': best_city['lng'],\n",
        "            'population': best_city.get('population', 0),\n",
        "            'confidence': confidence,\n",
        "            'source': 'fuzzy_match'\n",
        "        }\n",
        "\n",
        "\n",
        "# Build the matcher\n",
        "city_matcher = CityMatcher(cities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Testing City Matching\n",
        "\n",
        "Let's test the matcher with various query types:\n",
        "\n",
        "- **Typos**: \"San Fransisco\", \"Philidelphia\"\n",
        "- **Abbreviations**: \"St. Louis\", \"Ft. Worth\"\n",
        "- **Nicknames**: \"NYC\", \"LA\", \"Philly\"\n",
        "- **Ambiguous**: \"Portland\" (OR vs ME), \"Columbus\" (OH vs GA)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test queries\n",
        "test_queries = [\n",
        "    # Typos\n",
        "    (\"San Fransisco\", None),\n",
        "    (\"Philidelphia\", None),\n",
        "    (\"Seatle\", None),\n",
        "    (\"Huston\", \"TX\"),\n",
        "    \n",
        "    # Abbreviations and prefixes\n",
        "    (\"St. Louis\", None),\n",
        "    (\"Ft. Worth\", None),\n",
        "    \n",
        "    # Nicknames\n",
        "    (\"NYC\", None),\n",
        "    (\"LA\", \"CA\"),\n",
        "    (\"Philly\", None),\n",
        "    (\"Vegas\", None),\n",
        "    \n",
        "    # Ambiguous (multiple states)\n",
        "    (\"Portland\", None),\n",
        "    (\"Portland\", \"OR\"),\n",
        "    (\"Portland\", \"Maine\"),\n",
        "    (\"Columbus\", None),\n",
        "    (\"Columbus\", \"OH\"),\n",
        "]\n",
        "\n",
        "print(f\"{'Query':<20} {'State':<8} {'Matched City':<20} {'State':<6} {'Confidence':<10}\")\n",
        "print(\"=\" * 70)\n",
        "\n",
        "for query, state in test_queries:\n",
        "    result = city_matcher.get_coordinates(query, state)\n",
        "    \n",
        "    if result:\n",
        "        print(f\"{query:<20} {state or '-':<8} {result['city']:<20} {result['state']:<6} {result['confidence']:.2%}\")\n",
        "    else:\n",
        "        print(f\"{query:<20} {state or '-':<8} {'NO MATCH':<20}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Multi-Field Address Matching with SchemaIndex\n",
        "\n",
        "For more complex address matching, we can use SchemaIndex to match on multiple fields simultaneously:\n",
        "\n",
        "- **City**: Fuzzy match with abbreviation handling\n",
        "- **State**: Exact or fuzzy match\n",
        "- **ZIP**: Exact or partial match\n",
        "\n",
        "This is especially useful when we have partial information (e.g., city + ZIP but no state)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class AddressMatcher:\n",
        "    \"\"\"\n",
        "    Multi-field address matcher using SchemaIndex.\n",
        "    \n",
        "    Matches on city, state, and ZIP code with configurable weights.\n",
        "    Handles partial queries (e.g., just city + state, or city + ZIP).\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, cities: list):\n",
        "        self.cities = cities\n",
        "        \n",
        "        # Build schema: city (fuzzy), state (short), zips (tokens)\n",
        "        builder = fr.SchemaBuilder()\n",
        "        builder.add_field(\n",
        "            \"city\", \n",
        "            \"short_text\",\n",
        "            weight=10,  # City is most important\n",
        "            algorithm=\"jaro_winkler\",  # Good for names\n",
        "            normalize=\"lowercase\",\n",
        "            required=True\n",
        "        )\n",
        "        builder.add_field(\n",
        "            \"state\",\n",
        "            \"short_text\",\n",
        "            weight=5,  # State helps disambiguate\n",
        "            algorithm=\"exact_match\",  # States should match exactly\n",
        "            normalize=\"lowercase\"\n",
        "        )\n",
        "        builder.add_field(\n",
        "            \"zips\",\n",
        "            \"token_set\",\n",
        "            weight=8,  # ZIP is highly discriminative\n",
        "            separator=\" \"\n",
        "        )\n",
        "        \n",
        "        schema = builder.build()\n",
        "        self.index = fr.SchemaIndex(schema)\n",
        "        \n",
        "        # Add cities to index\n",
        "        print(\"Building multi-field address index...\")\n",
        "        for i, city in enumerate(cities):\n",
        "            # Normalize city name before indexing\n",
        "            normalized_city = normalize_city_name(city['city'])\n",
        "            \n",
        "            self.index.add({\n",
        "                'city': normalized_city,\n",
        "                'state': city['state_id'].lower(),\n",
        "                'zips': ' '.join(city.get('zips', [])[:10])  # Limit ZIPs per city\n",
        "            }, data=i)  # Store index for lookup\n",
        "        \n",
        "        print(f\"Indexed {len(self.index)} addresses\")\n",
        "    \n",
        "    def search(self, city: str = None, state: str = None, zip_code: str = None,\n",
        "               min_score: float = 0.5, limit: int = 5) -> list:\n",
        "        \"\"\"\n",
        "        Search for addresses matching the given criteria.\n",
        "        \n",
        "        Args:\n",
        "            city: City name (fuzzy matched)\n",
        "            state: State name or abbreviation\n",
        "            zip_code: ZIP code (can be partial, e.g., \"941\" matches \"94101\")\n",
        "            min_score: Minimum match score (0-1)\n",
        "            limit: Maximum results to return\n",
        "        \n",
        "        Returns:\n",
        "            List of matching addresses with scores\n",
        "        \"\"\"\n",
        "        query = {}\n",
        "        \n",
        "        if city:\n",
        "            query['city'] = normalize_city_name(city)\n",
        "        if state:\n",
        "            query['state'] = normalize_state(state).lower()\n",
        "        if zip_code:\n",
        "            query['zips'] = zip_code\n",
        "        \n",
        "        if not query:\n",
        "            return []\n",
        "        \n",
        "        results = self.index.search(query, min_score=min_score, limit=limit)\n",
        "        \n",
        "        # Enrich results with full city data\n",
        "        enriched = []\n",
        "        for r in results:\n",
        "            city_data = self.cities[r.data]\n",
        "            enriched.append({\n",
        "                'city': city_data['city'],\n",
        "                'state': city_data['state_id'],\n",
        "                'lat': city_data['lat'],\n",
        "                'lng': city_data['lng'],\n",
        "                'population': city_data.get('population', 0),\n",
        "                'score': r.score,\n",
        "                'field_scores': r.field_scores\n",
        "            })\n",
        "        \n",
        "        return enriched\n",
        "\n",
        "\n",
        "# Build the address matcher\n",
        "address_matcher = AddressMatcher(cities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test multi-field searches\n",
        "print(\"Multi-Field Address Matching Examples:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "test_cases = [\n",
        "    # City only (ambiguous)\n",
        "    {\"city\": \"Portland\"},\n",
        "    \n",
        "    # City + State (disambiguated)\n",
        "    {\"city\": \"Portland\", \"state\": \"Oregon\"},\n",
        "    \n",
        "    # City with typo + ZIP\n",
        "    {\"city\": \"San Fransisco\", \"zip_code\": \"94102\"},\n",
        "    \n",
        "    # Just ZIP code\n",
        "    {\"zip_code\": \"10001\"},\n",
        "    \n",
        "    # Nickname + state\n",
        "    {\"city\": \"Philly\", \"state\": \"PA\"},\n",
        "]\n",
        "\n",
        "for query in test_cases:\n",
        "    print(f\"\\nQuery: {query}\")\n",
        "    results = address_matcher.search(**query, limit=3)\n",
        "    \n",
        "    if results:\n",
        "        for r in results:\n",
        "            print(f\"  -> {r['city']}, {r['state']} (Score: {r['score']:.2%})\")\n",
        "            print(f\"     Field scores: {r['field_scores']}\")\n",
        "    else:\n",
        "        print(\"  -> No matches found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Building a Geocoding Fallback System\n",
        "\n",
        "Now let's build a complete geocoding fallback system that:\n",
        "\n",
        "1. Attempts primary geocoding (simulated API call)\n",
        "2. Falls back to fuzzy matching when API fails\n",
        "3. Returns coordinates with confidence scores\n",
        "4. Handles various input formats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def parse_address_components(address: str) -> dict:\n",
        "    \"\"\"\n",
        "    Parse a free-form address into components.\n",
        "    \n",
        "    Handles formats like:\n",
        "    - \"San Francisco, CA\"\n",
        "    - \"New York, New York 10001\"\n",
        "    - \"Austin TX\"\n",
        "    - \"90210\" (ZIP only)\n",
        "    \"\"\"\n",
        "    components = {\n",
        "        'city': None,\n",
        "        'state': None,\n",
        "        'zip_code': None\n",
        "    }\n",
        "    \n",
        "    # Clean the address\n",
        "    address = address.strip()\n",
        "    \n",
        "    # Extract ZIP code (5 digits or 5+4 format)\n",
        "    zip_match = re.search(r'\\b(\\d{5})(?:-\\d{4})?\\b', address)\n",
        "    if zip_match:\n",
        "        components['zip_code'] = zip_match.group(1)\n",
        "        address = address[:zip_match.start()] + address[zip_match.end():]\n",
        "    \n",
        "    # If only ZIP was provided, return early\n",
        "    address = address.strip(' ,')\n",
        "    if not address:\n",
        "        return components\n",
        "    \n",
        "    # Split by comma or common separators\n",
        "    parts = re.split(r'[,]+', address)\n",
        "    parts = [p.strip() for p in parts if p.strip()]\n",
        "    \n",
        "    if len(parts) >= 2:\n",
        "        # \"City, State\" format\n",
        "        components['city'] = parts[0]\n",
        "        # State might have extra words, take last 1-2 word token\n",
        "        state_part = parts[-1].strip()\n",
        "        state_words = state_part.split()\n",
        "        if len(state_words[-1]) == 2:  # Likely abbreviation\n",
        "            components['state'] = state_words[-1]\n",
        "        else:\n",
        "            components['state'] = state_part\n",
        "    elif len(parts) == 1:\n",
        "        # Single part - could be \"City State\" or just \"City\"\n",
        "        words = parts[0].split()\n",
        "        if len(words) >= 2 and len(words[-1]) == 2:\n",
        "            # Last word is likely state abbreviation\n",
        "            components['city'] = ' '.join(words[:-1])\n",
        "            components['state'] = words[-1]\n",
        "        else:\n",
        "            # Assume it's all city name\n",
        "            components['city'] = parts[0]\n",
        "    \n",
        "    return components\n",
        "\n",
        "\n",
        "class GeocodingFallback:\n",
        "    \"\"\"\n",
        "    Geocoding system with fuzzy matching fallback.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, cities: list):\n",
        "        self.city_matcher = CityMatcher(cities)\n",
        "        self.address_matcher = AddressMatcher(cities)\n",
        "    \n",
        "    def geocode(self, address: str, min_confidence: float = 0.7) -> dict:\n",
        "        \"\"\"\n",
        "        Geocode an address string.\n",
        "        \n",
        "        Returns:\n",
        "            Dict with lat, lng, city, state, confidence, source\n",
        "            or None if no match found\n",
        "        \"\"\"\n",
        "        # Parse address components\n",
        "        components = parse_address_components(address)\n",
        "        \n",
        "        # Strategy 1: Multi-field search if we have multiple components\n",
        "        if sum(1 for v in components.values() if v) >= 2:\n",
        "            results = self.address_matcher.search(\n",
        "                city=components['city'],\n",
        "                state=components['state'],\n",
        "                zip_code=components['zip_code'],\n",
        "                min_score=min_confidence,\n",
        "                limit=1\n",
        "            )\n",
        "            \n",
        "            if results:\n",
        "                r = results[0]\n",
        "                return {\n",
        "                    'city': r['city'],\n",
        "                    'state': r['state'],\n",
        "                    'lat': r['lat'],\n",
        "                    'lng': r['lng'],\n",
        "                    'confidence': r['score'],\n",
        "                    'source': 'multi_field_match',\n",
        "                    'field_scores': r['field_scores']\n",
        "                }\n",
        "        \n",
        "        # Strategy 2: Simple city lookup\n",
        "        if components['city']:\n",
        "            result = self.city_matcher.get_coordinates(\n",
        "                components['city'],\n",
        "                components['state'],\n",
        "                min_confidence\n",
        "            )\n",
        "            if result:\n",
        "                return result\n",
        "        \n",
        "        # Strategy 3: ZIP-only lookup\n",
        "        if components['zip_code']:\n",
        "            results = self.address_matcher.search(\n",
        "                zip_code=components['zip_code'],\n",
        "                min_score=0.5,\n",
        "                limit=1\n",
        "            )\n",
        "            if results:\n",
        "                r = results[0]\n",
        "                return {\n",
        "                    'city': r['city'],\n",
        "                    'state': r['state'],\n",
        "                    'lat': r['lat'],\n",
        "                    'lng': r['lng'],\n",
        "                    'confidence': r['score'] * 0.8,  # Lower confidence for ZIP-only\n",
        "                    'source': 'zip_lookup'\n",
        "                }\n",
        "        \n",
        "        return None\n",
        "\n",
        "\n",
        "# Initialize the fallback system\n",
        "geocoder = GeocodingFallback(cities)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the complete geocoding fallback system\n",
        "test_addresses = [\n",
        "    # Standard format\n",
        "    \"San Francisco, CA\",\n",
        "    \"New York, NY 10001\",\n",
        "    \n",
        "    # Typos\n",
        "    \"San Fransisco, California\",\n",
        "    \"Seatle WA\",\n",
        "    \n",
        "    # Abbreviations and nicknames\n",
        "    \"St. Louis, MO\",\n",
        "    \"NYC\",\n",
        "    \"Philly, PA\",\n",
        "    \n",
        "    # Partial information\n",
        "    \"Portland\",  # Ambiguous\n",
        "    \"Portland, OR\",  # Disambiguated\n",
        "    \"94102\",  # ZIP only\n",
        "    \n",
        "    # Unusual formats\n",
        "    \"Austin TX 78701\",\n",
        "    \"Las Vegas, Nevada\",\n",
        "]\n",
        "\n",
        "print(f\"{'Address':<35} {'Result':<25} {'Confidence':<12} {'Source'}\")\n",
        "print(\"=\" * 90)\n",
        "\n",
        "for addr in test_addresses:\n",
        "    result = geocoder.geocode(addr)\n",
        "    \n",
        "    if result:\n",
        "        location = f\"{result['city']}, {result['state']}\"\n",
        "        print(f\"{addr:<35} {location:<25} {result['confidence']:.1%}          {result['source']}\")\n",
        "    else:\n",
        "        print(f\"{addr:<35} {'NO MATCH':<25}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Confidence Scoring and Thresholds\n",
        "\n",
        "In a production geocoding system, confidence scores help you decide:\n",
        "\n",
        "- **High confidence (>0.9)**: Use coordinates directly\n",
        "- **Medium confidence (0.7-0.9)**: Use but flag for review\n",
        "- **Low confidence (0.5-0.7)**: Prompt user to confirm\n",
        "- **Very low (<0.5)**: Reject and ask for clarification\n",
        "\n",
        "Let's build a function that categorizes results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def geocode_with_quality(geocoder: GeocodingFallback, address: str) -> dict:\n",
        "    \"\"\"\n",
        "    Geocode with quality assessment.\n",
        "    \n",
        "    Returns result with quality rating:\n",
        "    - HIGH: >90% confidence, can use automatically\n",
        "    - MEDIUM: 70-90% confidence, use with caution\n",
        "    - LOW: 50-70% confidence, needs verification\n",
        "    - FAILED: <50% confidence or no match\n",
        "    \"\"\"\n",
        "    result = geocoder.geocode(address, min_confidence=0.5)\n",
        "    \n",
        "    if not result:\n",
        "        return {\n",
        "            'address': address,\n",
        "            'quality': 'FAILED',\n",
        "            'message': 'No match found',\n",
        "            'result': None\n",
        "        }\n",
        "    \n",
        "    confidence = result['confidence']\n",
        "    \n",
        "    if confidence >= 0.9:\n",
        "        quality = 'HIGH'\n",
        "        message = 'Confident match, safe to use automatically'\n",
        "    elif confidence >= 0.7:\n",
        "        quality = 'MEDIUM'\n",
        "        message = 'Probable match, consider verification for critical use'\n",
        "    elif confidence >= 0.5:\n",
        "        quality = 'LOW'\n",
        "        message = 'Uncertain match, manual verification recommended'\n",
        "    else:\n",
        "        quality = 'FAILED'\n",
        "        message = 'Match confidence too low'\n",
        "    \n",
        "    return {\n",
        "        'address': address,\n",
        "        'quality': quality,\n",
        "        'message': message,\n",
        "        'result': result\n",
        "    }\n",
        "\n",
        "\n",
        "# Test quality ratings\n",
        "quality_tests = [\n",
        "    \"San Francisco, CA\",      # Should be HIGH\n",
        "    \"San Fransisco, CA\",      # Should be MEDIUM (typo)\n",
        "    \"Sanfrancisco California\", # Should be LOW (multiple issues)\n",
        "    \"XYZ City, ZZ\",           # Should be FAILED\n",
        "]\n",
        "\n",
        "print(\"Quality Assessment Results:\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for addr in quality_tests:\n",
        "    assessment = geocode_with_quality(geocoder, addr)\n",
        "    \n",
        "    print(f\"\\nAddress: {addr}\")\n",
        "    print(f\"Quality: {assessment['quality']}\")\n",
        "    print(f\"Message: {assessment['message']}\")\n",
        "    \n",
        "    if assessment['result']:\n",
        "        r = assessment['result']\n",
        "        print(f\"Result: {r['city']}, {r['state']} (confidence: {r['confidence']:.1%})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Batch Processing for Scale\n",
        "\n",
        "When processing large address files, you need efficient batch operations.\n",
        "\n",
        "Let's process a batch of addresses and generate a report:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def batch_geocode(geocoder: GeocodingFallback, addresses: list) -> dict:\n",
        "    \"\"\"\n",
        "    Batch geocode addresses and return statistics.\n",
        "    \"\"\"\n",
        "    results = {\n",
        "        'HIGH': [],\n",
        "        'MEDIUM': [],\n",
        "        'LOW': [],\n",
        "        'FAILED': []\n",
        "    }\n",
        "    \n",
        "    for addr in addresses:\n",
        "        assessment = geocode_with_quality(geocoder, addr)\n",
        "        results[assessment['quality']].append(assessment)\n",
        "    \n",
        "    return results\n",
        "\n",
        "\n",
        "# Simulate a batch of addresses (mix of quality)\n",
        "batch_addresses = [\n",
        "    # Clean addresses\n",
        "    \"New York, NY\",\n",
        "    \"Los Angeles, CA\",\n",
        "    \"Chicago, IL\",\n",
        "    \"Houston, TX\",\n",
        "    \"Phoenix, AZ\",\n",
        "    \n",
        "    # Minor issues (typos, abbreviations)\n",
        "    \"San Fransisco, CA\",\n",
        "    \"Seatle, WA\",\n",
        "    \"St. Louis, MO\",\n",
        "    \"Ft. Worth, TX\",\n",
        "    \"NYC\",\n",
        "    \n",
        "    # More challenging\n",
        "    \"Portland\",  # Ambiguous\n",
        "    \"Philly\",\n",
        "    \"Vegas\",\n",
        "    \n",
        "    # Bad data\n",
        "    \"Unknown City, XX\",\n",
        "    \"123 Main Street\",  # Street address, not city\n",
        "]\n",
        "\n",
        "results = batch_geocode(geocoder, batch_addresses)\n",
        "\n",
        "# Print summary\n",
        "print(\"Batch Geocoding Results Summary\")\n",
        "print(\"=\" * 50)\n",
        "total = len(batch_addresses)\n",
        "\n",
        "for quality in ['HIGH', 'MEDIUM', 'LOW', 'FAILED']:\n",
        "    count = len(results[quality])\n",
        "    pct = count / total * 100\n",
        "    print(f\"{quality:<8}: {count:>3} ({pct:>5.1f}%)\")\n",
        "\n",
        "success_rate = (len(results['HIGH']) + len(results['MEDIUM'])) / total * 100\n",
        "print(f\"\\nSuccess Rate (HIGH+MEDIUM): {success_rate:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Production Considerations\n",
        "\n",
        "When deploying a geocoding fallback system:\n",
        "\n",
        "### Performance\n",
        "- **BK-tree**: O(log n) average lookup, excellent for city databases\n",
        "- **SchemaIndex**: Uses optimized indices per field type\n",
        "- **Memory**: ~50KB per 1,000 cities with full metadata\n",
        "\n",
        "### Accuracy Trade-offs\n",
        "- Higher `max_distance` catches more typos but increases false positives\n",
        "- State filtering dramatically improves accuracy for ambiguous cities\n",
        "- ZIP code matching provides strong disambiguation\n",
        "\n",
        "### Integration Pattern\n",
        "```python\n",
        "def geocode_address(address):\n",
        "    # Try primary API first\n",
        "    result = google_geocode(address)\n",
        "    if result:\n",
        "        return result\n",
        "    \n",
        "    # Fall back to fuzzy matching\n",
        "    fallback = geocoder.geocode(address)\n",
        "    if fallback and fallback['confidence'] >= 0.7:\n",
        "        return {\n",
        "            'lat': fallback['lat'],\n",
        "            'lng': fallback['lng'],\n",
        "            'source': 'fallback',\n",
        "            'confidence': fallback['confidence']\n",
        "        }\n",
        "    \n",
        "    return None  # Request manual review\n",
        "```\n",
        "\n",
        "### Monitoring\n",
        "- Track fallback usage rate (if >20%, check API health)\n",
        "- Log confidence distribution to tune thresholds\n",
        "- Review LOW confidence matches for pattern detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "In this guide, we built a complete address geocoding fallback system:\n",
        "\n",
        "1. **City normalization**: Handle abbreviations (St., Ft.), nicknames (NYC, LA), and typos\n",
        "2. **BK-tree matching**: Efficient edit-distance queries for typo correction\n",
        "3. **SchemaIndex multi-field**: Combine city, state, and ZIP for better accuracy\n",
        "4. **Confidence scoring**: Categorize results by reliability\n",
        "5. **Batch processing**: Handle large address files efficiently\n",
        "\n",
        "### Key Takeaways\n",
        "\n",
        "- **BK-trees** are ideal for short strings like city names (fast, memory-efficient)\n",
        "- **State filtering** is crucial for disambiguating common city names\n",
        "- **Normalization** before matching dramatically improves match rates\n",
        "- **Confidence thresholds** help balance automation vs. accuracy\n",
        "- **Multi-field matching** with SchemaIndex handles partial/ambiguous queries\n",
        "\n",
        "### When to Use This Approach\n",
        "\n",
        "- API rate limits or cost constraints\n",
        "- Offline/air-gapped environments\n",
        "- High-volume batch processing\n",
        "- As a fallback when primary geocoding fails"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
